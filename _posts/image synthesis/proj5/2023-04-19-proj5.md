---
title: "GAN Photo Editing"
layout: post
author: "Simon Seo"
categories: assignment
date: 2023-04-19
toc: true
style: image-synthesis-proj5
---


## Reference Papers
- [GAN Inversion: A Survey, `Xia` et al. (2021)](https://arxiv.org/abs/2101.05278)
- [Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?, `Abdal` et al. (2019)](https://arxiv.org/abs/1904.03189)



##1. Inverting the Generator



The original image that we will try to reconstruct by inverting a GAN generator:

![Alt text](data/part1/0_data.png){:width="384"}

<br>

Below we show some example outputs of image reconstruction using different loss functions, different types of generative models, and different types of latents space vectors.

<br>

|  | *perceptual loss only*  | *perceptual loss, $$l_1$$, $$l_2$$ loss* |
|:-:|:-:|:-:|
| *vanilla GAN + z* | ![Alt text](data/part1/perc/0_vanilla_z_0.01_1000.png){:width="300"} | ![Alt text](data/part1/perc%20l1%20l2/0_vanilla_z_0.1_1000.png){:width="300"} |
| *StyleGAN + z* | ![Alt text](data/part1/perc/0_stylegan_z_0.01_1000.png){:width="300"}      | ![Alt text](data/part1/perc%20l1%20l2/0_stylegan_z_0.1_1000.png){:width="300"} |
| *StyleGAN + w* | ![Alt text](data/part1/perc/0_stylegan_w_0.01_1000.png){:width="300"}      | ![Alt text](data/part1/perc%20l1%20l2/0_stylegan_w_0.1_1000.png){:width="300"} |
| *StyleGAN + w+* | ![Alt text](data/part1/perc/0_stylegan_w+_0.01_1000.png){:width="300"}     | ![Alt text](data/part1/perc%20l1%20l2/0_stylegan_w+_0.1_1000.png){:width="300"} |


##1. Interpolate your Cats

Now that we found a way to reconstruct the cat images from latent vectors, we can interpolate between the cat representations in the latent space and then map those interpolated latent vectors to the cat images using the same reconstruction method above.


<br>

|  | $$\text{cat}=A$$ | $$\text{cat}=A+t(B-A)$$ | $$\text{cat}=B$$ |
|:-:|:-:|:-:|:-:|
| Original | ![Alt text](data/part2/interpolate%2064/0.png){:width="180"} |  | ![Alt text](data/part2/interpolate%2064/1.png){:width="180"} |
| reconstruction <br/> using $$w+$$ vector | ![Alt text](data/part2/interpolate%2064/0_stylegan_w+.png){:width="180"} | ![Alt text](data/part2/interpolate%2064/1_stylegan_w+.gif){:width="180"} | ![Alt text](data/part2/interpolate%2064/1_stylegan_w+.png){:width="180"} |
| Original | ![Alt text](data/part2/interpolate%2064/2.png){:width="180"} |  | ![Alt text](data/part2/interpolate%2064/3.png){:width="180"} |
| reconstruction using <br/> $$w+$$ vector | ![Alt text](data/part2/interpolate%2064/2_stylegan_w+.png){:width="180"} | ![Alt text](data/part2/interpolate%2064/3_stylegan_w+.gif){:width="180"} | ![Alt text](data/part2/interpolate%2064/3_stylegan_w+.png){:width="180"} |

While in the latent space the vectors progress smoothly, the cat images do not. There are big jumps between each frame of interpolation. On the other hand, the quality of each frame is almost as good as any reconstruction of real cats. One thing to note is that there are some frames, like frame #9 in the top GIF, where some facial features are not pronounced enough: 

![Alt text](data/part2/interpolate%2064/1_stylegan_w+%20frame%209.png){:width="300"}

This phenomenon is interesting because when we train the generator model, we sample Gaussian noise from the latent space, where assumably most training data lies in. This may signify that some cat images lie slightly outside the distribution of cat images in the latent space.




##1. Scribble to Image

Now let's draw cats, and get an approximation of the drawings as cat images.


![Alt text](data/part3/regularization/2_data.png){:width="300"}


‚òù This scribble image is approximated as cat images below. The weight of the regularization term has a big effect in this case, because the scribble image lies completely outside the distribution of our usual cat images.

<br>

|  | iteration=500 | iteration=1000 |
|:-:|:-:|:-:|
|regularization <br/> weight = 0  | ![Alt text](data/part3/regularization/2_stylegan_w+_0.5_500%20reg=0.png){:width="300"} | ![Alt text](data/part3/regularization/2_stylegan_w+_0.5_1000%20reg=0.png){:width="300"} |
|regularization <br/> weight = 1  | ![Alt text](data/part3/regularization/2_stylegan_w+_0.5_500%20reg=1.png){:width="300"} | ![Alt text](data/part3/regularization/2_stylegan_w+_0.5_1000%20reg=1.png){:width="300"} |
|regularization <br/> weight = 3  | ![Alt text](data/part3/regularization/2_stylegan_w+_0.5_500%20reg=3.png){:width="300"} | ![Alt text](data/part3/regularization/2_stylegan_w+_0.5_1000%20reg=3.png){:width="300"} |

With little regularization, our reconstruction optimization will try to find the latent vector that will map to an image closest to the scribble, period. However, we may not want that. We want the final image to still look like a cat. So where do we draw the line? Experimentally (visually), the weight of regularization term that works best with perceptual loss should maintain the colours and structure of the scribble while also still looking like a cat.

Here are some good cases where the results turned out quite nicely. 

|  |  |
|:-:|:-:|
| ![Alt text](data/part3/reg3/0_data.png){:width="200"}  |  ![Alt text](data/part3/reg3/0_stylegan_w+_0.01_1000.png){:width="200"} |
| ![Alt text](data/part3/reg3/1_data.png){:width="200"}  |  ![Alt text](data/part3/reg3/1_stylegan_w+_0.01_1000.png){:width="200"} |
| ![Alt text](data/part3/reg3/2_data.png){:width="200"}  |  ![Alt text](data/part3/reg3/2_stylegan_w+_0.01_1000.png){:width="200"} |
| ![Alt text](data/part3/reg3/3_data.png){:width="200"}  |  ![Alt text](data/part3/reg3/3_stylegan_w+_0.01_1000.png){:width="200"} |
| ![Alt text](data/part3/reg3/4_data.png){:width="200"}  |  ![Alt text](data/part3/reg3/4_stylegan_w+_0.01_250.png){:width="200"} |
| ![Alt text](data/part3/reg3/6_data.png){:width="200"}  |  ![Alt text](data/part3/reg3/6_stylegan_w+_0.01_1000.png){:width="200"} |
| ![Alt text](data/part3/reg3/9_data.png){:width="200"}  |  ![Alt text](data/part3/reg3/9_stylegan_w+_0.01_1000.png){:width="200"}|

And just for fun, I also tried the same thing but instead of a scribble, I used an (AI generated) image of a person just to see how they would look like as a cat. Okay, the generator forced something out, but let's not.


<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!-- <script type="text/javascript" src="{{ site.baseurl }}/assets/js/MathJax/MathJax.js"></script> -->
<!-- <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script> -->
